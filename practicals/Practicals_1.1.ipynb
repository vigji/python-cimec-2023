{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a44e75",
   "metadata": {},
   "source": [
    "# Practicals for lecture 1.1\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vigji/python-cimec/blob/main/practicals/Practicals_1.1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a4f38",
   "metadata": {},
   "source": [
    "## More on `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff75e9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d801e0",
   "metadata": {},
   "source": [
    "#### 1.1.0 Stats over numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b7be63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.random.normal to initialize a vector of 1000 numbers of mean 10 and standard deviation 3. \n",
    "# Then calculate the actual mean and standard deviation of the array you got using numpy.\n",
    "arr = np.random.normal(10, 3, 1000)\n",
    "\n",
    "np.mean(arr), np.std(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c3ffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def download_meteo_data(start_date=\"2022-01-01\", end_date=\"2022-12-31\",\n",
    "                        latitude=\"45.88204\", longitude=\"11.03647\",\n",
    "                        data=\"temperature_2m\"):\n",
    "    \"\"\"Download meteo historical data from open-meteo.com.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        start_date : str\n",
    "            Beginning of time series.\n",
    "            \n",
    "        end_date : str\n",
    "            End of time series.\n",
    "            \n",
    "        latitude : float\n",
    "            Latitude of the time series.\n",
    "            \n",
    "        longitude : float\n",
    "            Longitude of the time series.\n",
    "            \n",
    "        data : str\n",
    "            Data to download. One of \"temperature_2m\", \"relativehumidity_2m\",\n",
    "            \"precipitation\", \"snowfall\", \"windspeed_10m\".\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "        np.array\n",
    "            1D array of timestamps\n",
    "        np.array\n",
    "            1D array of data, sampled every hour (24 points per day)\n",
    "\n",
    "    \"\"\"\n",
    "    BASE_URL = \"https://archive-api.open-meteo.com/v1/\"\n",
    "    query = f\"archive?latitude={latitude}&longitude={longitude}&start_date={start_date}&end_date={end_date}&hourly={data}\"\n",
    "\n",
    "    r = requests.get(BASE_URL + query)\n",
    "    json_dict = json.loads(r.text)\n",
    "    \n",
    "    if \"hourly\" not in json_dict.keys():\n",
    "        print(json_dict)\n",
    "        return None, None\n",
    "    else:\n",
    "        return (np.array(json_dict[\"hourly\"][k]) for k in [\"time\", data])\n",
    "\n",
    "\n",
    "tststamps_array, temp_array = download_meteo_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72cd709",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_array.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ce96d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell above to download an array of temperatures in Rovereto during 2022. \n",
    "# Temperatures data are sampled every hour. \n",
    "\n",
    "# Reshape the array to be a matrix of shape (n_days, n_hours). \n",
    "n_days = 365\n",
    "n_hours = 24\n",
    "\n",
    "temp_mat = np.reshape(temp_array, (n_days, n_hours))\n",
    "\n",
    "# Plot it with plt.matshow() to check if it makes sense. Change the colormap to be divergent around 0.\n",
    "plt.imshow(temp_mat, aspect=\"auto\", cmap=\"RdBu_r\")\n",
    "plt.set_xlabel=\"Hour\"\n",
    "plt.set_ylabel=\"Day\"\n",
    "plt.colorbar(label=\"T (Â°C)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e8ae37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use plt.plot to show temperatures for all days (each day a line). You can do it in a for loop,\n",
    "# or in one call of the function given the right dimension order for the data matrix!\n",
    "# for day_idx in range(n_days):\n",
    "#     plt.plot(temp_mat[day_idx, :])\n",
    "plt.plot(temp_mat.T, c=\"0.6\")\n",
    "\n",
    "\n",
    "\n",
    "# Compute the average temperature line over days, and plot it on top of the individual day lines.\n",
    "# Look into the plt.plot documentation to make the lines of the individual days gray and the average red.\n",
    "\n",
    "avg_daily_temps = np.mean(temp_mat, axis=0)\n",
    "plt.plot(avg_daily_temps, c=\"r\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6189b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the temperatures data, create one-dimensional arrays with the minimum, mean and maximum temperatures\n",
    "# of each day.\n",
    "mean_t = np.mean(temp_mat, axis=1)\n",
    "min_t = np.min(temp_mat, axis=1)\n",
    "max_t = np.max(temp_mat, axis=1)\n",
    "\n",
    "# Look into the documentation for the plt.fill_between() function, and use it to make a plot \n",
    "# where you represent the temperature range for every day of the year.\n",
    "x_array = np.arange(n_days)\n",
    "plt.fill_between(x_array, min_t, max_t)\n",
    "plt.plot(x_array, mean_t, c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ee87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat the same, but now representing the 25th-75th percentile range for every day.\n",
    "\n",
    "perc25_t = np.percentile(temp_mat, 25, axis=1)\n",
    "perc75_t = np.percentile(temp_mat, 75, axis=1)\n",
    "\n",
    "# Look into the documentation for the plt.fill_between() function, and use it to make a plot \n",
    "# where you represent the temperature range for every day of the year.\n",
    "x_array = np.arange(n_days)\n",
    "plt.fill_between(x_array, perc25_t, perc75_t)\n",
    "plt.plot(x_array, mean_t, c=\"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e9bc07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are Murphy's laws true? Does it rain more on weekends?\n",
    "\n",
    "# Write the docs of download_meteo_data(), and use it to download precipitation data from 2022.\n",
    "# Tip: change the end_date argument to be end_date=\"2023-01-02\" to have a multiple of 7 days!\n",
    "# Tip2: check out a calendar to see which weekday the array will start from.\n",
    "\n",
    "# Reshape the matrix as we did before, and compute cumulative (or average) precipitations per day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e98e0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Then, reshape the daily averages array to be of shape (n_weeks, n_weekdays)\n",
    "\n",
    "# Finally, take the average over the n_weeks dimension and plot median precipitation for each weekday!\n",
    "# Bonus points: represent the dispersion of the data (std or percentiles) using plt.fill_between().\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f899850",
   "metadata": {},
   "source": [
    "#### 1.1.1 Vectorizations and indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f1f2f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at daily excursions instead of absolute temperatures!\n",
    "\n",
    "# Write a function that takes as input a matrix and subtracts from each row \n",
    "# the minimum value of that row, in a loop. \n",
    "# Make sure you do not change the original matrix when running the function!\n",
    "\n",
    "# Now, write a second function that does the same in a single vector operation:\n",
    "\n",
    "\n",
    "# Then, test it over the temperature data matrix. Use plt.matshow to visualize it before and after\n",
    "# the offset subtraction. \n",
    "# Tip: you can use plt.subplots() to show multiple plots next to each other\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc443c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use np.argsort() to sort a whole array based on the values of another array!\n",
    "\n",
    "# For a full ranking of the most rainy days of 2022, sort\n",
    "# the timestamps array based on the sorting of precipitation array. \n",
    "# Make sure the first element matches the result that you have got with np.argmax!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13795ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spike detection (optional!)\n",
    "\n",
    "# Run the function below to generate an synthetic extracellular\n",
    "# recording for a neuron. Plot the trace; can you see the spikes?\n",
    "\n",
    "# Write a function to detect spikes! Think about a good strategy to do this\n",
    "# before starting.\n",
    "# The function should take the trace as input, and return the index of each spike\n",
    "# as the output.\n",
    "# Make sure you do not get more than one index for each spike!\n",
    "\n",
    "# Pro challenge: if you can, try not to write any loop.\n",
    "\n",
    "# Then, write a crop_event function that takes as inputs:\n",
    "#    - the recording array\n",
    "#.   - the spike indexes\n",
    "#    - a n_points variable specifying the number of points to crop before and after the spike\n",
    "#\n",
    "# And returns a (n_spikes, n_points*2) matrix of spike events cropped out of the recording!\n",
    "# Plot the matrix you get. If you want you can try to normalize it with the function you wrote for\n",
    "# the daily temperatures excursion exercise!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "962079b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spike_trace(trace_length=60, firing_rate=1, noise_sigma = 0.03):\n",
    "    \"\"\"Function to generate a fake extracellular recording.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        trace_length : float\n",
    "            Duration of the recording in seconds.\n",
    "        \n",
    "        firing_rate : float\n",
    "            Average firing rate of the neuron in Hz.\n",
    "            \n",
    "        noise_sigma : float\n",
    "            Noise level.\n",
    "            \n",
    "            \n",
    "    Returns:\n",
    "    --------\n",
    "        np.array\n",
    "            Fake recording shape.\n",
    "    \n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    FS = 10000  # sampling frequency\n",
    "    n = int(trace_length * FS)  # number of samples\n",
    "    \n",
    "    # Generate spike shape template as a difference of Gaussians.\n",
    "    # A horrible bunch of magic numbers - do not imitate!\n",
    "    x = np.arange(30)\n",
    "    spike_template = np.exp(-(x - 10)**2/6) - np.exp(-(x - 12)**2/16)*0.8\n",
    "\n",
    "    # Generate spike times from a gaussian distribution:\n",
    "    spikes_times = np.random.poisson(firing_rate / FS, n)\n",
    "    \n",
    "    # Convolve dirac delta functions of spike times with spike template:\n",
    "    trace = np.convolve(spikes_times, spike_template)[:n]\n",
    "\n",
    "    # Add some gaussian noise:\n",
    "    trace += np.random.normal(0, noise_sigma, n)\n",
    "    \n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420e25ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
