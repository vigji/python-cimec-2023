{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03a44e75",
   "metadata": {},
   "source": [
    "# Practicals for lecture 1.1\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vigji/python-cimec/blob/main/practicals/Practicals_1.1.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2a4f38",
   "metadata": {},
   "source": [
    "## More on `numpy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4266000",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d801e0",
   "metadata": {},
   "source": [
    "#### 1.1.0 Creating numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b74729e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use np.random.normal to initialize a vector of 1000 numbers of mean 10 and standard deviation 3. \n",
    "# Then calculate the actual mean and standard deviation of the array you got using numpy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a02a931",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def download_meteo_data(start_date=\"2022-01-01\", end_date=\"2022-12-31\",\n",
    "                        latitude=\"45.88204\", longitude=\"11.03647\",\n",
    "                        data=\"temperature_2m\"):\n",
    "    \"\"\"Download meteo historical data from open-meteo.com.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        start_date : str\n",
    "            Beginning of time series.\n",
    "            \n",
    "        end_date : str\n",
    "            End of time series.\n",
    "            \n",
    "        latitude : float\n",
    "            Latitude of the time series.\n",
    "            \n",
    "        longitude : float\n",
    "            Longitude of the time series.\n",
    "            \n",
    "        data : str\n",
    "            Data to download. One of \"temperature_2m\", \"relativehumidity_2m\",\n",
    "            \"precipitation\", \"snowfall\", \"windspeed_10m\".\n",
    "            \n",
    "    Returns\n",
    "    -------\n",
    "        np.array\n",
    "            1D array of timestamps\n",
    "        np.array\n",
    "            1D array of data, sampled every hour (24 points per day)\n",
    "\n",
    "    \"\"\"\n",
    "    BASE_URL = \"https://archive-api.open-meteo.com/v1/\"\n",
    "    query = f\"archive?latitude={latitude}&longitude={longitude}&start_date={start_date}&end_date={end_date}&hourly={data}\"\n",
    "\n",
    "    r = requests.get(BASE_URL + query)\n",
    "    json_dict = json.loads(r.text)\n",
    "    \n",
    "    if \"hourly\" not in json_dict.keys():\n",
    "        print(json_dict)\n",
    "        return None, None\n",
    "    else:\n",
    "        return (np.array(json_dict[\"hourly\"][k]) for k in [\"time\", data])\n",
    "\n",
    "\n",
    "tststamps_array, temp_array = download_meteo_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce35cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the cell above to download an array of temperatures in Rovereto during 2022. \n",
    "# Temperatures data are sampled every hour. \n",
    "\n",
    "# Reshape the array to be a matrix of shape (n_days, n_hours). \n",
    "\n",
    "# Plot it with plt.matshow as a sanity check.\n",
    "\n",
    "# Use plt.plot to show temperatures for all days (each day a line). You can do it in a for loop,\n",
    "# or in one call of the function given the right dimension order for the data matrix!\n",
    "\n",
    "# Compute the average temperature line over days, and plot it on top of the individual day lines.\n",
    "# Look into the plt.plot documentation to make the lines of the individual days gray and the average red.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea4d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the temperatures data, create one-dimensional arrays with the minimum, mean and maximum temperatures\n",
    "# of each day.\n",
    "\n",
    "# Look into the documentation for the plt.fill_between() function, and use it to make a plot \n",
    "# where you represent the temperature range for every day of the year.\n",
    "\n",
    "# Do the same but now representing the 25th-75th percentile range for every day.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d901abce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Are Murphy's laws true? Does it rain more on weekends?\n",
    "# Download precipitation data using download_meteo_data() and specifying the data argument.\n",
    "# Tip: You can also change the end_date to be end_date=\"2023-01-02\" \n",
    "#      to get all days of the last week of the year.\n",
    "\n",
    "# Reshape the matrix as we did before, and compute sum (or average) precipitations per day.\n",
    "\n",
    "# Then, reshape the daily averages array to be of shape (n_weeks, n_weekdays)\n",
    "\n",
    "# Finally, take the average over the n_weeks dimension and plot median precipitation for each weekday!\n",
    "# Bonus points: compute some other statistics to represent the dispersion of the data\n",
    "#               using plt.fill_between()."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "969d6098",
   "metadata": {},
   "source": [
    "#### 1.1.1 Vectorizations and indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29eceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's have a look at daily excursions instead of absolute temperatures!\n",
    "\n",
    "# Write a function that takes a matrix and subtracts from each row the minimum value of the row\n",
    "# in a loop. Make sure you do not change the original matrix inside the function!\n",
    "\n",
    "# Now, write a second function that does the same in a single vector operation:\n",
    "\n",
    "\n",
    "# Then, test it over the temperature data matrix. Use plt.matshow to visualize it before and after\n",
    "# the offset subtraction. \n",
    "# Tip: you can use plt.subplots() to show multiple plots next to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d603108c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use np.argsort() to sort a whole array based on the values of another array!\n",
    "\n",
    "# For a full ranking of the most rainy days of 2022, sort\n",
    "# the timestamps array based on the sorting of precipitation array. \n",
    "# Make sure the first element matches the result that you got with np.argmax!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8dc6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spike detection (optional, difficoult exercise!)\n",
    "\n",
    "# Run the function below to generate an synthetic extracellular\n",
    "# recording for a neuron. Plot the trace; can you see the spikes?\n",
    "\n",
    "# Write a function to detect spikes! Think about a good strategy to do this\n",
    "# before starting.\n",
    "# The function should take the trace as input, and return the index of each spike\n",
    "# as the output.\n",
    "# If you can, try not to write any loop!\n",
    "\n",
    "\n",
    "# Then, write a crop_event function that takes as inputs:\n",
    "#    - the recording array\n",
    "#.   - the spike indexes\n",
    "#    - a n_points variable specifying the number of points to crop before and after the spike\n",
    "#\n",
    "# And returns a (n_spikes, n_points*2) matrix of spike events cropped out of the recording!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "330fdbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_spike_trace(trace_length=60, firing_rate=1, noise_sigma = 0.03):\n",
    "    \"\"\"Function to generate a fake extracellular recording.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "        trace_length : float\n",
    "            Duration of the recording in seconds.\n",
    "        \n",
    "        firing_rate : float\n",
    "            Average firing rate of the neuron in Hz.\n",
    "            \n",
    "        noise_sigma : float\n",
    "            Noise level.\n",
    "            \n",
    "            \n",
    "    Returns:\n",
    "    --------\n",
    "        np.array\n",
    "            Fake recording shape.\n",
    "    \n",
    "    \"\"\"\n",
    "    np.random.seed(42)\n",
    "    FS = 10000  # sampling frequency\n",
    "    n = int(trace_length * FS)  # number of samples\n",
    "    \n",
    "    # Generate spike shape template as a difference of Gaussians.\n",
    "    # A horrible bunch of magic numbers - do not imitate!\n",
    "    x = np.arange(30)\n",
    "    spike_template = np.exp(-(x - 10)**2/6) - np.exp(-(x - 12)**2/16)*0.8\n",
    "\n",
    "    # Generate spike times from a gaussian distribution:\n",
    "    spikes_times = np.random.poisson(firing_rate / FS, n)\n",
    "    \n",
    "    # Convolve dirac delta functions of spike times with spike template:\n",
    "    trace = np.convolve(spikes_times, spike_template)[:n]\n",
    "\n",
    "    # Add some gaussian noise:\n",
    "    trace += np.random.normal(0, noise_sigma, n)\n",
    "    \n",
    "    return trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d5c41d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
