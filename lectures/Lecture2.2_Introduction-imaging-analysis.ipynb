{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca811a3",
   "metadata": {},
   "source": [
    "# Python for (open) Neuroscience\n",
    "\n",
    "_Lecture 2.2_ - Working with image data\n",
    "\n",
    "Luigi Petrucco\n",
    "\n",
    "Jean-Charles Mariani\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vigji/python-cimec/blob/main/lectures/Lecture2.0_Real-world-Python.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e727046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214cdc3f",
   "metadata": {},
   "source": [
    "## Images/Imaging data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa265c2",
   "metadata": {},
   "source": [
    "Imaging data pops out in many different places!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90bfdb9",
   "metadata": {},
   "source": [
    "Anatomy...\n",
    "<img src=\"https://nordiclifescience.org/wp-content/public_html/2020/03/2004OEKG30Mar-Global-winner-Ainara-Pintor-immunostaining-of-a-mouse-brain-slice-with-two-fluorophores-e1585637968987-760x380.jpg\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1ba5f9c",
   "metadata": {},
   "source": [
    "Functional imaging...\n",
    "<img src=\"https://hazimsos.files.wordpress.com/2014/02/brain_500.gif\"  width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4990a4",
   "metadata": {},
   "source": [
    "Behavior / video analysis...\n",
    "<img src=\"https://edspace.american.edu/openbehavior/wp-content/uploads/sites/1502/2020/12/3mice.gif\"  width=\"300\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65d7d80c",
   "metadata": {},
   "source": [
    "Visual tasks...\n",
    "<img src=\"https://www.jneurosci.org/content/jneuro/42/43/8125/F1.large.jpg\"  width=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8dccea",
   "metadata": {},
   "source": [
    "## Working with images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5f60a",
   "metadata": {},
   "source": [
    "When we work with any kind of image, or stacks of images, we have to think about them as matrices. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ffb8975",
   "metadata": {},
   "source": [
    "Numbers in the matrix map the intensity of the signal at every pixel."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137964da",
   "metadata": {},
   "source": [
    "![animal](./files/imageschema.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13652066",
   "metadata": {},
   "source": [
    "If the image is a plain 2D, **monocromatic image**, the data is a (height, width) matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22b712b7",
   "metadata": {},
   "source": [
    "### Common image formats\n",
    "\n",
    "- `.png`: 2D colored images, LOSS-LESS compression\n",
    "- `.jpeg`: 2D colored images, LOSSY compression format - we loose some information at high levels of compression!\n",
    "- `.tiff`: both 2D, 3D, or ND images, common for image stacks (volumes, timelapses...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35f8e6a",
   "metadata": {},
   "source": [
    "### Scientific imaging formats\n",
    "- `.nrrd` (imaging data)\n",
    "- `.nii.gz` (imaging data)\n",
    "- `.ome.tiff` (microscopy data)\n",
    "- ...endless others"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6246da9a",
   "metadata": {},
   "source": [
    "## Libraries to work with images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a58de2f",
   "metadata": {},
   "source": [
    "There are countless packages to read and write images!What you choose will depend a lot on the actual data and libraries you will be working with. The most common ones:\n",
    "\n",
    "- `PIL`: RGB images\n",
    "- `tifffile`: `.tiff` files and image stacks\n",
    "- `imageio`: RGB images, `.tiff` files and image stacks\n",
    "- `nibabel`: `.nii.gz` imaging data\n",
    "- `opencv`: any kind of image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5676dca",
   "metadata": {},
   "source": [
    "### Image readers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef6035e2",
   "metadata": {},
   "source": [
    "Most packages provide us with an image reader class.\n",
    "\n",
    "We instantiate a reader object from our data file, and we use its methods to read it!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4197205a",
   "metadata": {},
   "source": [
    "### The `PIL` package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5af6ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To use this package, first `pip install Pillow` from the terminal\n",
    "import PIL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60297384",
   "metadata": {},
   "source": [
    "Let's have a look at a simple `.jpeg` image! To work with plain images, `Pillow` is an excellent and very powerful library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1b8fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "img = Image.open(\"./files/octopus.jpg\")  # this creates an image object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d1556a",
   "metadata": {},
   "outputs": [],
   "source": [
    "img  # instead of printing this will directly show the color image in the notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a940602",
   "metadata": {},
   "source": [
    "### Image metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb416b2",
   "metadata": {},
   "source": [
    "Metadata have different degrees of sofistication depending on where your image is from. Often your data acquisition devices save images with a bunch of parameters about the acquisition, that are kept in the image metadata.\n",
    "\n",
    "Here we just have some info about the jpeg compression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac2705b",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "967d6dd8",
   "metadata": {},
   "source": [
    "### Image data content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301748a5",
   "metadata": {},
   "source": [
    "Your reader will then have a method to retrieve the actual image data as an array. In this case, we can directly convert it to a numpy array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badb44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert image to numpy array:\n",
    "data_array = np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d7f348",
   "metadata": {},
   "source": [
    "## Image dimensions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25460f36",
   "metadata": {},
   "source": [
    "If the image is a plain 2D, monocromatic image, the data is a (height, width) matrix.\n",
    "\n",
    "Additional dimensions can encode:\n",
    " - **different channels** (typically 3 for RGB images, 4 for RGBA images (with transparency), but depends on the data)\n",
    " - **the depth** (if the data is volumetric)\n",
    " - **the time axis** (if the data is acquired through time as in a video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08613bd1",
   "metadata": {},
   "source": [
    "In our case, since this is an RGB image, the shape will be (heigth, width, channels). We use three different channels (R,G,B to encode the color)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3775c8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9693c23",
   "metadata": {},
   "source": [
    "### Color spaces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fcf1ed8",
   "metadata": {},
   "source": [
    "[Color spaces](https://en.wikipedia.org/wiki/Color_space) are generally considered 3D business (at least)! As in, we always need triplets to encode a color. RGB is not the only option, there's other spaces:\n",
    "- `RGB`: Red, Green, Blue - monitors\n",
    "- `CMYK`: Cyan, Magenta, Yellow, Black - printers\n",
    "- `HLS`: Hue, Luminance, Saturation - the only one that makes sense\n",
    "\n",
    "Maybe we'll see them again in the lecture on data visualization!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b876a0cb",
   "metadata": {},
   "source": [
    "Let's have a look at each channel in our RGB data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628409d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In those plots, the colors are arbitrary:\n",
    "f, axs = plt.subplots(1, 3, figsize=(9, 4))\n",
    "\n",
    "for channel_i, (ax, title) in enumerate(zip(axs, [\"Red\", \"Green\", \"Blue\"])):\n",
    "    ax.imshow(data_array[:, :,channel_i])\n",
    "    ax.set(title=title)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae32b108",
   "metadata": {},
   "source": [
    "If we pass a 3D array with 3 elements over the third axis to plt.imshow, it will assume it is an RGB image and represents it as such!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1756c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we pass an RGB image, so imshow knows what the real colors are:\n",
    "plt.figure()\n",
    "plt.imshow(data_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b41ef5",
   "metadata": {},
   "source": [
    "### Images axes conventions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5537453a",
   "metadata": {},
   "source": [
    "In images we encode rows top to bottom, and columns left to right!\n",
    "\n",
    "- **Image coordinates**: `i, j` (`i` top >> bottom, `j` left >> right);\n",
    "\n",
    "- **Cartesian coordinates**: `x, y` (`x` bottom >> top, `y` left >> right);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7d0e24",
   "metadata": {},
   "source": [
    "The `0, 0` pixel in an image is the top left corner; the `0, 0` coordinate is the bottom left coordinate of the plane:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c782fa",
   "metadata": {},
   "source": [
    "![animal](./files/imageschema-02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df9c1a3",
   "metadata": {},
   "source": [
    "Sometimes this can be VERY CONFUSING if you are working with images!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb67de5",
   "metadata": {},
   "source": [
    "## The image bit depth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "615733a3",
   "metadata": {},
   "source": [
    "Pixel are encoded with a specific number of bits!\n",
    "\n",
    "The higher the number of bits, the more possible values the image pixel can have, the heavier your data will be.\n",
    "\n",
    "The number of bits encoding each pixel is called the bit depth of the image! \n",
    "\n",
    "Typical depths are either 8 (values from 0 to 255) or 16 (values from 0 to 65535). Different file formats support different bit depths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49619cf1",
   "metadata": {},
   "source": [
    "The bit depth will correspond with the `dtype` of our array! In our case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3726f40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_array.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d9bfc0",
   "metadata": {},
   "source": [
    "### The image histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936d8157",
   "metadata": {},
   "source": [
    "A common way to describe an image is the image histogram. This is just the distribution of pixel values over the range defined by the bit depth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1a1ce3a",
   "metadata": {},
   "source": [
    "Let's create a monocromatic (grayscale) image from the red channel:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa55ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "grayscale_img =  data_array[:, :,channel_i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36597e7f",
   "metadata": {},
   "source": [
    "We can now look at the histogram for this image by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4c1791",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1, 2, figsize=(6, 2.5))\n",
    "axs[1].hist(grayscale_img.flatten(), np.arange(255))\n",
    "axs[0].imshow(grayscale_img, cmap=\"gray\")\n",
    "axs[1].set(xlabel=\"Intensity\", ylabel=\"Counts\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b2e7ab",
   "metadata": {},
   "source": [
    "Remember that the maximum value that we can encode in this array is 255!! If for any reason values get shifted above this number, python takes the 255 module of the new values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2932b5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_img = grayscale_img + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37fc496",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1, 2, figsize=(6, 2.5))\n",
    "axs[1].hist(shifted_img.flatten(), np.arange(255))\n",
    "axs[0].imshow(shifted_img, cmap=\"gray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b65c8e9e",
   "metadata": {},
   "source": [
    "To prevent this, we have to change the dtype of the stack before shifting it. **This will increase the space needed to store it in memory!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b99dd1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "shifted_img = grayscale_img.astype(np.uint16) + 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa7c733",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, axs = plt.subplots(1, 2, figsize=(6, 2.5))\n",
    "\n",
    "axs[1].hist(shifted_img.flatten(), np.arange(400))\n",
    "axs[0].imshow(shifted_img, cmap=\"gray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399b8047",
   "metadata": {},
   "source": [
    "(a stupid thing in this case - we are using a larger bit depth but encoding the same value range!)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9070a55",
   "metadata": {},
   "source": [
    "### A balanced image histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb8f519",
   "metadata": {},
   "source": [
    "Being aware of how many bits are encoding our data is important to make sure we use them well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae90c8b2",
   "metadata": {},
   "source": [
    "Sometimes an image can end up being **saturated** (e.g., over-exposed). In this case, values from the camera/imaging sistem are clipped to the maximum value of our bit depth. This is bad - we loose information!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e23fc461",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_saturated_img(img):\n",
    "    shifted_img = img.astype(np.uint16)*1.4\n",
    "    shifted_img[shifted_img >= 255] = 255\n",
    "    return shifted_img\n",
    "\n",
    "def get_underexposed_img(img):\n",
    "    return img // 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7f2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "saturated = get_saturated_img(grayscale_img)  # a saturated image\n",
    "\n",
    "_, axs = plt.subplots(1, 2, figsize=(6, 2.5))\n",
    "axs[1].hist(saturated.flatten(), np.arange(256))\n",
    "axs[0].imshow(saturated, cmap=\"gray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff1008",
   "metadata": {},
   "source": [
    "Other times, we might not be using well all the levels available in our encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3b9978",
   "metadata": {},
   "outputs": [],
   "source": [
    "underexposed = get_underexposed_img(grayscale_img)  # an underexposed image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bea34d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "_, axs = plt.subplots(1, 2, figsize=(6, 2.5))\n",
    "axs[1].hist(underexposed.flatten(), np.arange(0, 256, 5))\n",
    "axs[0].imshow(underexposed, cmap=\"gray\")\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a8e318",
   "metadata": {},
   "source": [
    "## Binary images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48304355",
   "metadata": {},
   "source": [
    "We can create binary (`True`/`False`) images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53937c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "THRESHOLD = 180\n",
    "binarized = grayscale_img > THRESHOLD\n",
    "_, axs = plt.subplots(1, 2, figsize=(6, 2.5))\n",
    "axs[0].imshow(grayscale_img, cmap=\"gray\")\n",
    "axs[1].imshow(binarized, cmap=\"gray\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522acac4",
   "metadata": {},
   "source": [
    "It is common to use a binary image as a mask for further data processing. For example, we can look at the RGB image after masking it with the binarized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88366325",
   "metadata": {},
   "outputs": [],
   "source": [
    "masked_rgb_img = img * binarized[:, :, np.newaxis]  # note how here we use broadcasting!\n",
    "plt.figure()\n",
    "plt.imshow(masked_rgb_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac43066",
   "metadata": {},
   "source": [
    "(Practical 2.2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad03cc",
   "metadata": {},
   "source": [
    "## Creating images with Pillow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "123dc7b9",
   "metadata": {},
   "source": [
    "Sometimes we might need to generate images programmatically. The Pillow library is a great way to do this!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d579d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "# an empty image with a background color:\n",
    "pil_img  = Image.new( mode = \"RGB\", size=(400, 300), color=(200,)*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "748e5518",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can look at the image in a cell just by putting it at the end of a cell:\n",
    "pil_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0989ea1",
   "metadata": {},
   "source": [
    "Let's create a Draw() object to paint stuff on our empty image:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29bcbf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw = ImageDraw.Draw(pil_img)  # painter object to draw stuff on our image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e3700",
   "metadata": {},
   "source": [
    "We can now create shapes on the image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cad4eaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "draw.ellipse((125, 100, 175, 150), fill=(174, 48, 51), outline=None, width=2)\n",
    "draw.rectangle((225, 100, 275, 150), fill=None, outline=(174, 48, 51))\n",
    "\n",
    "for i in range(3):\n",
    "    draw.line((100+i*40, 200+i*10, 300-i*40, 200+i*10), fill=(174, 48, 51), width=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44af88e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa54c389",
   "metadata": {},
   "source": [
    "We can also include text!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09fb2af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "font = ImageFont.truetype(\"LibertinusSans-Regular.otf\", 40)\n",
    "draw.text((95, 20), \"Hello World.\", fill=(240, )*3, font=font)  # add text to the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837c830d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f538f33",
   "metadata": {},
   "source": [
    "There's many other things we can do with Pillow!\n",
    " - resize images\n",
    " - combine multiple images\n",
    " - mask images\n",
    " - frame-by-frame animations \n",
    " - ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb0bddaa",
   "metadata": {},
   "source": [
    "(Practicals 2.2.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "880785e6",
   "metadata": {},
   "source": [
    "## Manipulating images as numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77b998c4",
   "metadata": {},
   "source": [
    "We can also just work with images as if they were numpy arrays. E.g., for cropping them we can just index them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79885695",
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_img = grayscale_img[:400, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6717c91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,2, figsize=(6, 3))\n",
    "for ax, im in zip(axs, [grayscale_img, crop_img]):\n",
    "    ax.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78862e79",
   "metadata": {},
   "source": [
    "To rotate them 90 degrees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2ec172",
   "metadata": {},
   "outputs": [],
   "source": [
    "rot_img = np.rot90(grayscale_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c3f6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, axs = plt.subplots(1,2, figsize=(6, 3))\n",
    "for ax, im in zip(axs, [grayscale_img, rot_img]):\n",
    "    ax.imshow(im)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd730e94",
   "metadata": {},
   "source": [
    "### Image convolution"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eff8348",
   "metadata": {},
   "source": [
    "There's a bunch of cool operations we can perform by convolving images with a certain kernel:\n",
    "\n",
    "- blur an image (denoise)\n",
    "- edge detection\n",
    "- binary mask erosion or contraction\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56753bd",
   "metadata": {},
   "source": [
    "### Advanced video analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13742834",
   "metadata": {},
   "source": [
    "There's  great ML tools to perform advanced segmentation in an automatic ways! Make sure you read what your options are before starting doing a lot of manual work :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8832cd45",
   "metadata": {},
   "source": [
    "SegmentAnything\n",
    "\n",
    "<img src=\"https://aicurious.io/posts-data/2023-04-22-create-a-segment-anything-labeling-tool-any-labeling/ezgif-2-6b2f1c5a89.gif\"  width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33bf3e45",
   "metadata": {},
   "source": [
    "DeepLabCut\n",
    "<img src=\"https://edspace.american.edu/openbehavior/wp-content/uploads/sites/1502/2020/12/3mice.gif\"  width=\"400\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48875cce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08260dc8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:course_env]",
   "language": "python",
   "name": "conda-env-course_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
