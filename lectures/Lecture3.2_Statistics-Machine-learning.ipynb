{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ca811a3",
   "metadata": {},
   "source": [
    "# Python for (open) Neuroscience\n",
    "\n",
    "_Lecture 3.0_ - Introduction to Statistics and Machine learning in Pyhton\n",
    "\n",
    "Luigi Petrucco\n",
    "\n",
    "Jean-Charles Mariani"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582bbe72",
   "metadata": {},
   "source": [
    "## Classical statistics using Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "923e4247",
   "metadata": {},
   "source": [
    "Disclaimer: I know very little about statistics!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bcfe94",
   "metadata": {},
   "source": [
    "No, Python will not tell you what tests to use...\n",
    "\n",
    "...but `scipy` module provides functions for pretty much any kind of classical statistics you might want to compute!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3120a301",
   "metadata": {},
   "source": [
    "### Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ad1cce",
   "metadata": {},
   "source": [
    "#### Mean, median, mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b34c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "data = np.random.normal(0, 1, 1000)\n",
    "\n",
    "print('Mean: {}'.format(np.mean(data)))\n",
    "print('Median: {}'.format(np.median(data)))\n",
    "print('Mode: {}'.format(stats.mode(data)[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a525db1",
   "metadata": {},
   "source": [
    "#### Standard deviation, variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01d1174",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Standard deviation: {np.std(data)}')\n",
    "print(f'Variance: {np.var(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411cd23",
   "metadata": {},
   "source": [
    "#### Percentiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8ee081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f' 95Perencile: {np.percentile(data, 95)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94f76a3b",
   "metadata": {},
   "source": [
    "## Statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86bbc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b007b769",
   "metadata": {},
   "source": [
    "### One-sample tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59eb9830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-sample t-test\n",
    "stats.ttest_1samp(data, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c5146cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-sample Wilcoxon signed-rank test\n",
    "stats.wilcoxon(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fea293f3",
   "metadata": {},
   "source": [
    "# Two-sample t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1aa16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = np.random.normal(0, 1, 1000)\n",
    "stats.ttest_ind(data, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe9e0b",
   "metadata": {},
   "source": [
    "# Two-sample Wilcoxon rank-sum test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8a5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Two-sample Wilcoxon rank-sum test\n",
    "stats.ranksums(data, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c81119",
   "metadata": {},
   "source": [
    "#### Paired samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e77a3430",
   "metadata": {},
   "source": [
    "# Paired t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a39bc0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.ttest_rel(data, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ade240c",
   "metadata": {},
   "source": [
    "# Paired Wilcoxon signed-rank test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1256fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.wilcoxon(data, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737a65a",
   "metadata": {},
   "source": [
    "# One-way ANOVA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa57e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.normal(0, 1, 1000)\n",
    "data2 = np.random.normal(0, 1, 1000)\n",
    "data3 = np.random.normal(-1, 1, 1000)\n",
    "stats.f_oneway(data, data2, data3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396faa5d",
   "metadata": {},
   "source": [
    "# Kolmogorov-Smirnov test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5680576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_norm = np.random.normal(0, 1, 1000)\n",
    "data_unif = np.random.uniform(0, 1, 1000)\n",
    "\n",
    "stats.kstest(data_norm, 'norm')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0de319",
   "metadata": {},
   "source": [
    "### Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dd34dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.normal(0, 1, 1000)\n",
    "data2 = np.random.normal(0, 1, 1000)\n",
    "stats.pearsonr(data, data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3efb184",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.random.normal(0, 1, 1000)\n",
    "data2 = data + np.random.normal(0, 1, 1000)\n",
    "stats.pearsonr(data, data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502ebc02",
   "metadata": {},
   "source": [
    "## Normality tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc3a542",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test normality of data\n",
    "data = np.random.normal(0, 1, 1000)\n",
    "stats.normaltest(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7a30b7",
   "metadata": {},
   "source": [
    "# Curve fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3453517a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "# Define the function to fit\n",
    "def func(x, a, b, c):\n",
    "    return a * np.exp(-b * x) + c\n",
    "\n",
    "# Generate data\n",
    "x = np.linspace(0, 4, 50)\n",
    "ydata = func(x, 2.5, 1.3, 0.5) + 0.2 * np.random.normal(size=len(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db113f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the data\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.scatter(x, ydata, label='data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f71d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the data\n",
    "popt, pcov = curve_fit(func, x, ydata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642d69ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.scatter(x, ydata, label='data')\n",
    "plt.plot(x, func(x, *popt), c=\"k\", label='fit')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e7ce212",
   "metadata": {},
   "source": [
    "(Practicals 3.2.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95c63f1",
   "metadata": {},
   "source": [
    "# Visualizing data using seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cbb5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "iris.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a36fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(iris, hue='species', height=2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8704ce40",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.jointplot(x=\"petal_width\", y=\"sepal_length\", data=iris, kind='reg');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abd0b214",
   "metadata": {},
   "source": [
    "## Advanced statistics using statsmodels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0be1a30",
   "metadata": {},
   "source": [
    "The `statsmodels` module provides a more complete set of statistical tools, including:\n",
    "- Linear models\n",
    "- Generalized linear models\n",
    "- Multivariate statistics\n",
    "- ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94461bc0",
   "metadata": {},
   "source": [
    "### Linear models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99836e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "data = sm.datasets.get_rdataset('Guerry', 'HistData').data\n",
    "data = data[['Lottery', 'Literacy', 'Wealth', 'Region']].dropna()\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "471349d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.ols('Lottery ~ Literacy + Wealth + Region', data=data)\n",
    "results = model.fit()\n",
    "print(results.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54c2fec",
   "metadata": {},
   "source": [
    "# Machine learning using scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "322e79e9",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05bbe04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e20248",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled = scaler.transform(X_train)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679bcf76",
   "metadata": {},
   "source": [
    "Other scalers for max-min normalization ( MinMaxScaler), etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16134119",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram equalization\n",
    "data = np.random.normal(0, 1, 1000)\n",
    "quantile_trasformer = preprocessing.QuantileTransformer(n_quantiles=1000)\n",
    "trasf = quantile_trasformer.fit_transform(data.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a864c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trasf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ca4abb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(data, trasf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943a5bd",
   "metadata": {},
   "source": [
    "# Dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "876760ec",
   "metadata": {},
   "source": [
    "### Principal component analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08fc3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# A simple tw-dimension dataset:\n",
    "from sklearn import datasets\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "X = np.array([[-1, -1], [-2, -1], [-3, -2], [1, 1], [2, 1], [3, 2]])\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cda52cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2)\n",
    "pca.fit(X)\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "print(pca.singular_values_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "842cd8af",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3)  )\n",
    "plt.scatter(X[:, 0], X[:, 1])\n",
    "plt.plot([0, pca.components_[0, 0]], [0, pca.components_[0, 1]], 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d094c61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed = pca.transform(X)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.scatter(transformed[:, 0], transformed[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5463a8",
   "metadata": {},
   "source": [
    "# Splitting data into training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b752a5",
   "metadata": {},
   "source": [
    "## Scikit-learn offers a function to split data into training and test sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39306cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X, y = make_blobs(n_samples=50000, centers=5, n_features=5, random_state=0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, stratify=y, random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b479cdba",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "plt.scatter(X_train[:, 0], X_train[:, 1], c=Y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e69944ce",
   "metadata": {},
   "source": [
    "There's also tools to loop over multiple splits of the data:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf867eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "X = np.array([[1, 2], [3, 4], [1, 2], [3, 4],\n",
    "              [0, 2], [1, 2], [5, 2], [0, 1]])\n",
    "kf = KFold(n_splits=4)\n",
    "kf.get_n_splits(X)\n",
    "# print(kf)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05117e1b",
   "metadata": {},
   "source": [
    "# Data clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d99aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Create two clusters of data and merge them into one dataset:\n",
    "X, y = make_blobs(n_samples=50000, centers=4, cluster_std=2,\n",
    "                  n_features=2, random_state=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35cda88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3772625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# Split data in test and train:\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, y, random_state=50)\n",
    "\n",
    "kmeans = KMeans(init=\"k-means++\", n_clusters=4, n_init=10)\n",
    "kmeans.fit(X_train)\n",
    "\n",
    "Y_predicted = kmeans.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3d30e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(3, 3))\n",
    "\n",
    "plt.scatter(X_test[:, 0], X_test[:, 1], c=Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa5dec6",
   "metadata": {},
   "source": [
    "# Measuring accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286bddcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03585d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix(Y_test, Y_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb191e8",
   "metadata": {},
   "source": [
    "(Practicals 3.2.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c942ab1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python [conda env:course_env]",
   "language": "python",
   "name": "conda-env-course_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
